TASK1:
ğŸ“ˆ AAPL Stock Price Prediction using Linear Regression
ğŸ§  Objective
Build a simple machine learning model to predict the next day's closing price of Apple Inc. (AAPL) stock using historical trading data.

ğŸ“Š Dataset Used
Source: yfinance API

Period: January 1, 2020 â€“ December 31, 2024

Features: Open, High, Low, Volume

Target: Next dayâ€™s Close price (shifted by -1)

ğŸ› ï¸ Model Applied
Linear Regression (scikit-learn)

Training set: 80% of the data

Testing set: 20% of the data



TASK 2:

ğŸŒ¸ Iris Dataset Analysis & Visualization
ğŸ¯ Objective
Explore and visualize the famous Iris dataset to understand feature distributions and relationships between species.

ğŸ“ Dataset Used
Source: seaborn.load_dataset('iris')

Features: sepal_length, sepal_width, petal_length, petal_width

Target: species (Setosa, Versicolor, Virginica)

Shape: 150 rows Ã— 5 columns

ğŸ§ª Exploratory Data Analysis (EDA)
Dataset overview: .shape, .columns, .head(), .info(), .describe()

Visualization techniques:

Pairplot (sns.pairplot) showing feature relationships by species

Histogram of each feature with bin and edge styling

Boxplot for all features grouped by species to highlight median, spread, and outliers

ğŸ“Œ Insights
Petal features are more distinguishing between species than sepal features.

Pairplots reveal clear cluster separation among species.

Boxplots show species-specific ranges and variance across feature dimensions.

ğŸ“Œ Key Results & Findings
The model successfully learns a linear relationship between daily price movements and volume trends.

Predicted vs actual closing prices are visualized using Matplotlib for evaluation.


TASK 3:


ğŸ  Housing Price Prediction: Regression Model Comparison
ğŸ¯ Objective
Predict house prices using multiple regression models and compare their performance for accuracy and reliability.

ğŸ“ Dataset Used
Source: Uploaded CSV (Housing.csv)

Features: Area, bedrooms, bathrooms, furnishing status, road access, etc.

Target Variable: price

ğŸ§¼ Data Preprocessing
Binary categorical features (yes/no) encoded to 0/1

furnishingstatus handled via one-hot encoding (semi, unfurnished)

Numerical features scaled with StandardScaler for model fairness

ğŸ¤– Models Applied
Model	Technique
Linear Regression	Baseline model
Gradient Boosting Regressor	Ensemble method with 100 trees
ğŸ“Š Evaluation Metrics
Model	MAE (Mean Absolute Error)	RMSE (Root Mean Squared Error)
Linear Regression	MAE_X, RMSE_X
Gradient Boosting	MAE_Y, RMSE_Y
Replace MAE_X, RMSE_X, etc. with your actual printed scores.

ğŸ“‰ Visualization
Scatter plot comparing predicted vs. actual prices for both models

Diagonal line (k--) added to highlight ideal prediction

ğŸ“Œ Key Findings
Gradient Boosting provides improved accuracy over simple linear regression.

Encoding and scaling significantly enhance model performance and generalization.




Last day prediction (based on final feature row): Predicted next day's closing price: $XXX.XX
